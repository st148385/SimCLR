

# Devices
num_cpu_threads = 10
set_devices.num_cpu_threads = %num_cpu_threads
set_devices.soft_device_placement = False

# Input Pipeline
ds_name = 'cifar10'    #'cifar10'  #'tf_flowers'
tfds_path = '~\\tensorflow_datasets'        # if linux ~/tensorflow_datasets on server /data/public/tensorflow_datasets

size_batch = 512            # This is NOT the batch size of semi-supervised training epochs, it is just the one of unsupervised simclr training epochs
dataset_image_size = 32     # After data-augmentation, all images have size (dataset_image_size,dataset_image_size,3)

gen_pipeline_train.ds_name = %ds_name
gen_pipeline_train.tfds_path = %tfds_path
gen_pipeline_train.size_batch = %size_batch
gen_pipeline_train.b_shuffle = True
gen_pipeline_train.dataset_cache = False
gen_pipeline_train.size_buffer_cpu = 5
gen_pipeline_train.shuffle_buffer_size = 50000
gen_pipeline_train.num_parallel_calls = %num_cpu_threads
gen_pipeline_train.x_size = %dataset_image_size
gen_pipeline_train.color_distortion_strength = 0.5      # use s=0.5 for cifar10/100. s=1.0 should be better for imagenet/flowers
plot_dataset.dataset_name = %ds_name


# Input Pipeline for the semi-supervised learning epochs of the semi-supervsied SimCLR training
gen_pipeline_ssl_eval.ds_name = %ds_name
gen_pipeline_ssl_eval.tfds_path = %tfds_path
gen_pipeline_ssl_eval.RESIZE_TO_RES = %dataset_image_size
gen_pipeline_ssl_eval.BATCH_SIZE = 64
gen_pipeline_ssl_eval.minCrop = 0.5
gen_pipeline_ssl_eval.color_distortion_strength = 0.5
gen_pipeline_ssl_eval.useNpercentOfCifar10 = 15


# Training parameters
train.n_epochs=11
train.SSLeveryNepochs=10
train.learning_rate_noScheduling=0.01
train.lr_max_ifScheduling=0.01
train.warmupDuration=0.1   # percentage of total training-steps in decimal form [0,1]
train.save_period = 1
train.size_batch = %size_batch
train.tau = 0.275
train.use_split_model = True
train.use_2optimizers = False
train.use_learning_rate_scheduling = True

